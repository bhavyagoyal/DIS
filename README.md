# Daily Insight Sharing (DIS) 2018 

##### List of papers that we discussed in our reading group at Visual Understanding Lab
Papers are mostly related to Image Retrieval, Deep Metric Learning, Image Recognition, Generative Adversarial Networks and applications

* [3/14] **Why M Heads are Better than One: Training a Diverse Ensemble of Deep Networks**
[arxiv](https://arxiv.org/abs/1511.06314)
<details><summary></summary>
(+) Sharing lower layers is a little better than full ensemble. <br>
(+) Can learn a lesson from their failure. Don't mess with the independency of ensemble<br>
(+) Interesting metric called oracle accruacy of ensemble (T if any learner is correct)<br>
(-) Not accepted. A little improvement of performance<br>
</details>
<br>

* [3/14] **Metric Learning-based Generative Adversarial Network**
[arxiv](https://arxiv.org/abs/1711.02792)
<details><summary></summary>
(+) Try to combining metric learning & GAN which is related to our work<br>
(-) Applying metric learning for better GAN, while we need GAN for metric learning<br>
</details>
<br>

* [3/19] **Averaging weights leads to wider optima and better generalization**
[arxiv](https://arxiv.org/abs/1803.05407)
<details><summary></summary>
(+) Well citation and summary of previous findings about SGD and loss function<br>
(-) Limited understanding of super-high dimensional space by 1D/2D projection<br>
</details>
<br>

* [3/22] **Meta-Learning for Semi-Supervised Few-Shot Classification**
[arxiv](https://arxiv.org/abs/1803.00676)
<details><summary></summary>
(+) First paper for semi-supervised meta-learning (metric learning)<br>
(+) Semi-supervised setting with distractor is realistic<br>
(+) Benchmark for semi-supervised metric learning<br>
(-) The method is somewhat heuristic<br>
</details>
<br>

* [3/26] **Directional Statistics-based Deep Metric Learning for Image Classification and Retrieval**
[arxiv](https://arxiv.org/abs/1802.09662)
<details><summary></summary>
(+) New approach for searching each class meaning direction in metric learning<br>
(+) Well-organized retrieval experiment using von-mises-fisher distribution<br>
(-) Easy to understand, but the performance of SOP retrieval performance isn't high<br>
</details>
<br>

* [3/26] **Don't Decay the Learning Rate, Increase the Batch Size**
[arxiv](https://arxiv.org/abs/1711.00489)
<details><summary></summary>
(+) "Increasing batchsize A times" is equivalent to "decreasing learning rate A times"<br>
(+) Possible gain in speed<br>
(-) no improve in the accuracy<br>
() The title says it all, it's more like an empirical paper<br>
</details>
<br>

